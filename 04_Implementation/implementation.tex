\chapter{Implementierung}

Die Implementierung beschreibt ganz grundlegende technische Details der Umsetzung. Das kann von konkreten Entscheidungen, wie der Wahl einer bestimmten Programmiersprache oder bestimmter Software-Bibliotheken, bis hin zu Auszügen aus dem Programmcode gehen.

Typischer Umfang der Implementierung: 5-10 Seiten BA, 15-20 Seiten MA.

\section{Learning Managment System}
Viele LMS sind auf dem Markt angeboten. Ein geeignete Plattform für das Projekt wird ausgewahlt. Auf diesem LMS wird ein Unterricht über Infusionsvorbereitung gestaltet. Paar Lernmethoden beispielsweise VR Übung werden in dem Unterricht eingesetzt. 

 \subsection{LMS Auswahl}
 Laut Capterra stehen mehr als 400 LMS mit Web Applikation zu Verfügung. Jede LMS hat eigne Merkmale. Moodle wird als die LMS Plattform in diesem Projekt eingesetzt.
 
 Der größte Vorteil von Moodle für das Projekt ist, dass Moodle eine kostenlos open source LMS Plattform ist. Das heißt, dass es möglich ist, die Moodle gratis auf eigenem Server zu installieren, mit eigener Datenbank zu verbinden und nach eigenen Anforderungen anzupassen.
 
 Durch die vielfältige Aktivitäten in Moodle beispielsweise Aufgabe, Befragung, Test usw. können unterschiedliche Lernmethode eingesetzt werden. Mit dem Plugin System kann man selbst mit PHP eigene Aktivität schreiben und in Moodle integrieren, dadurch der zweite und dritte Form der Verbindung zwischen LMS und WebVR, die in Kapitel Konzeption genannt sind, implementiert werden können.
 
 In Moodle können auch Arbeitsmaterialien wie Buch, Datei, Link usw. angeboten werden. Bei diesem Projekt wird der Benutzer durch den URLs in Moodle zu der WebVR Applikation geleitet, wie die erste Form, die in Konzeption beschrieben wird. 
 
 \subsection{Unterricht}
 Bei dem Unterricht Infusion Vorbereitung werden fünf Arbeitsmaterialien (drei Links, eine Datei und ein Textseite) und eine Aktivität eingesetzt. Die drei Links leiten jeweils auf einer Erklärung über Infusionsvorbereitung in Text, einer Erzählung über 5-R-Regel in Text und einem Video über Infusionsvorbereitung auf Youtube um. Die Datei ist ein Diagramm, damit der Ablauf der Vorbereitung einer Infusion graphisch dargestellt wird.
 
 Die Textseite ist die Zugang der praktische Übung in VR Umgebung. Die Methoden der Interaktion für unterschiedlichen Geräten werden zuerst informiert. Danach wird der Ablauf mit dem Diagramm noch einmal wiederholt. Und die acht Abschnitte in der Übung werden bezeichnet. Zum Abschluss werden acht Links aufgelistet, die auf dem entsprechenden Abschnitt in der VR Übung umleiten.
 
 Am Ende des Unterrichtes wird die Aktivität Test angeboten. Dadurch wird das Effekt des Lernens überprüft. Und das Ergebnis wird in Moodle gespeichert.
 
 Die VR Übung und der Test sind wiederholbar, um die Lernenden zu helfen, die Fertigkeit richtig zu beherrschen.
 
 image: Unterricht und Textseite .........
 
\section{WebVR Übung}
Die Implementierung der WebVR Übung ist der Schwerpunkt dieses Projektes. .........

 \subsection{Framework Auswahl}
 
 Um die Ziele dieses Projektes zu erreichen, muss das ausgewählte Framework folgende Anforderungen erfüllen:
 
 \begin{enumerate}
     \item Das Projekt kann gut mit LMS kommunizieren. Die Kommunikation kann durch URL oder Datenbank realisiert werden.
     \item Das Framework kann unterschiedlichen Geräte unterstützen, z.B. PC, Smartphone und HMD.
     \item Das Projekt kann auf eigene Server bewahrt.
     \item Die Nutzung ist kostenlos.
     \item Reichliche Dokumentationen und erreichbare Community stehen zu Verfügung.
     \item Das Framework soll lange Zeit unterstützt und am besten kontinuierlich entwickelt werden.
 \end{enumerate}
 
 Im Kapitel Stand der Technik wird die Technologie der WebVR vorgestellt. Fünf Frameworks oder Game Engines davon sind benutzbar, um ein WebVR Applikation effizient zu entwickeln, nämlich , Unity, Play Canvas, Vizor, React 360 und A-Frame.
 
 \begin{itemize}
     \item \textbf{Unity} ist ein umfassende Game Engine. Viele built-in Funktionen stehen zu Verfügung. Mit das Plugin von Mozilla kann ein Projekt als WebVR Applikation exportiert werden. Allerdings wird das Projekt in einem Rahmen stellt. In diesem Rahmen ist die Entwicklung hoch effizient. Aber es ist schwierig, mit der Dinge außer dem Rahmen beispielsweise LMS anzupassen. Desegen wird Unity nicht ausgewählt.
     \item \textbf{Play Canvas} ist ein webbasiert Game Engine. Damit kann das Projekt direkt als WebVR Applikation exportiert werden. Aber wenn man die Applikation auf eigne Server bewahren möchte, muss man monatlich zahlen.
     \item \textbf{Vizor} ist eine webbasierte visuelle WebVR Plattform. Die Scripts wird durch Blueprint geschrieben. Die Stärke ist, die 360 Grade oder VR Szene darzustellen. Die Unterstützung für Interaktion reicht nicht für dieses Projekt.
     \item \textbf{React 360} basiert teilweise auf three.js und wird von Facebook entwickelt. Die Logik der Entwicklung von React 360 ist gleich wie die bekannte JavaScript Bibliothek React im Bereich Frontend-Entwicklung. Allerdings wurde React 360 noch nicht vorgestellt, wenn dieses Projekt fängt an. Damals existierte nur der Vorfahr von React 360, nämlich React VR. Aber die Funktionalität von React VR war nicht reif genug, dieses Projekt zu entwickeln.
     \item \textbf{A-Frame} ist ein von Mozilla entwickeltes kostenloses open source WebVR Framework. Es bietet die größte Freiheit, das Projekt zu manipulieren. Außerdem werden unterschiedlichen Geräte unterstützt. Mit A-Frame werden die Funktionen von three.js in einem Entity-Component System eingewickelt. Die Features von three.js werden vererbt. Die Lösungen der Probleme über der Entwicklung können entweder in der Community von A-Frame oder der Community von three.js gefunden werden.
 \end{itemize}
 
 image: Editor von Frameworks .........
 
 A-Frame kann alle Anforderungen erfüllen. Deshalb wird nach dem Vergleich für A-Frame entschieden.
 
 \subsection{Projekt bauen}
 Im Bereich Web Entwicklung bieten zwei beliebte Werkzeugen, npm und Webpack, die Mögilichkeit, die Entwicklung einer Web Applikation zu projektieren, damit wird die Entwicklung effizienter gemacht. 
 
 Npm (Node Package Manager) ist ein Packetmanager für die JavaScript-Luafzeitumgebung Node.js. Mit npm ist es einfach, die auf npm gespeicherte Pakete(Softwares) zu benutzen. Die Abhängigkeit der Paketen werden durch npm automatisch behandelt. Alle benutzte Pakete werden in einer Datei eingepackt, sodass wird der Einsatz auf dem Server erleichtert.
 
 image: npm .........
 
 Webpack ist ein auf npm gespeichertes Werkzeug, die verwendete und geschriebene Dateien zu organisieren. Während der Entwicklung einer Web Applikation werden vielen Dateien beispielsweise Javascript Dateien, HTML Dateien, CSS Dateien, Bilder Dateien usw. benutzt. Die Dateien sind getrennt, aber mit einander verbindet. Solche dezentralisiere Struktur führt zum hohen Aufwand, das Projekt auf Server zu bewähren. Durch Webpack werden die Dateien während der Entwicklung bündig verpackt und komprimiert.
 
 image: webpack .........
 
 Webpack-dev-server ist ein zusätzliches Werkzeug von Webpack. Dadurch wird die verpackte JavaScript Dateien automatisch kompiliert und die Webseite automatisch aktualisiert, solange die Code geändert werden.
 
 Währen der Entwicklung einer Web Applikation können die CORS (Cross-Origin Resource Sharing) Errors auftauchen, wenn die lokale zugängliche Datei direkt in Browser aufgerufen wird, um das Effekt der Code anzuschauen. Der Grund ist, dass zur Sicherheit die Browsers Same-Origin-Policy benutzen. Das heißt, dass es untersagt wird, auf Objekte (zum Beispiel Grafiken) zuzugreifen, die von einer anderen Webseite stammen oder deren Speicherort nicht der Origin entspricht. Die von Browser direkt aufgerufenen lokalen Dateien gelten nicht als Same-Origin requests sodern Cross-Origin requests.
 
 image: cross origin .........
 
 Http-server ist auch ein auf npm gespeichertes Werkzeug, dadurch ein Server (localhost) auf eigene PC erstellt werden kann. Und ein ausgewählter Ordner auf dem PC wird als das Wurzelverzeichnis des Servers eingerichtet. Alle Dateien in diesem Ordner gelten als in dem gleichen Origin, sodass die CORS Errors behoben werden.
 
 image: projekt screenshot 
 
 \subsection{Zustände Management für Fortschritte}
 Im Kapitel Konzeption werden die Erkennung und Feedback Fortschritte erzählt. Wie werden die Fortschritte in der Applikation implementiert, wird in diesem Kapitel erklärt.
 
 Um die Fortschritte zu definieren, wird die Konzeption \glqq state container\grqq von der Technik Redux importiert. Jede Objekt in der VR Szene hat eigne Zustand, zum Beispiel Position. Die betreffende Zustände werden geändert, wenn der Prozess der Applikation betrieben wird. Die Sammlung der Zustände der allen Objekten wird als \glqq state container\grqq bezeichnet. Durch die Kombination der Zustände wird der Fortschritt der Übung notiert.
 
 Dann ist der ganze Ablauf eines Fortschritts, dass eine Aktivität des Benutzers auf ein Objekt erst erkannt wird. Danach wird die betreffende Zustände geändert. Laut der Änderung der Zustände wird die entsprechende Aktivität des Objektes durchgeführt, was als Feedback an dem Benutzer gilt.
 
 image: Fortschritt Diagramm .........
 
  \subsubsection{Beobachter (en. Observer Pattern)}
  Beobachter ist ein Entwurfsmuster (en. Design Pattern) aus dem Bereich Softwareentwicklung. Es ist geeignet, der Fortschritte zu realisieren.
  
  Die Funktionalität davon ist ähnlich wie Twitter. Ein Fußballspieler hat einen Account von Twitter, damit er Nachrichten freigibt. Die Fans von dem Fußballspieler \glqq follow\grqq dem Fußballspieler auf Twitter. Wenn der Fußballspieler Nachrichten weiter freigibt, werden die Fans benachrichtet.
  
  Im Bereich Softwareentwicklung wird der Fußballspieler als \glqq Observable\grqq oder \glqq Subject\grqq bezeichnet. Die Fans werden als \glqq Observer\grqq bezeichnet. Die Aktivität \glqq follow\grqq ist \glqq Subscribe\grqq. Die Benachrichtigung heißt \glqq Notify\grqq.
  
  \includegraphics[width=\textwidth]{images/observerPattern.jpeg}
  
  Um der das Oberserver Pattern zu implementieren, wird ein Class \glqq Observable\grqq bei diesem Projekt erstellt.
  
  image: Observable .........
  
  Während der Erstellung einer Observable wird ein Array generiert, um die Observers zu speichern. Durch die Funktionen subscribe und unsubscribe können die Observers in dem Array eingefügt oder von dem Array ausgezogen werden. Die Observers(Funktionen) sollen ein Parameter haben, um die Nachrichten von Observer zu empfangen. Wenn die Funktion Notify aufgerufen wird, werden alle Observers in dem Array nacheinander aufgerufen. Der Parameter der Funktion Notify wird als Parameter der Observers eingesetzt, sodass die Nachrichten auszuteilen.
  
  
  \subsubsection{Zustände Management}
  
  Um das Zustand Management zu realisieren, wird ein Class stateIndex geschrieben. Da fast alle Objekt in der Szene mit diesem Class verbinden und das einzige \glqq state container\grqq referenzieren, wird das Class als \glqq static\grqq Class definiert.
  
  Mit init Funktion werden alle Zustände initialisiert. Die Initialisierung liegt an dem Query string in URL. Das Query string ist ein Teil von URL, dadurch der  Parameter bei dem \glqq request\grqq zusammen an dem Server geschickt. Bei dieser Applikation soll das Query string die Ziffer des ausgewählten Abschnitt sein. Mit dem Query string wird die Zustände nach dem Ausgewählten Abschnitt initialisiert.
  
  Während der Initialisierung wird eine Entität von Observable erstellt, um die Benachrichtigung vorzubereiten.
  
  Die init Funktion wird nur ein mal durchgeführt, wenn die Applikation aufgerufen.
  
  image: URL mit Query string .........
  
  Zu Sicherheit darf die Zustände von andere Objekt nicht erreichen. Deswegen werden die Funktionen von Class stateIndex angeboten, um die Zustände zu manipulieren.
  
  \begin{itemize}
      \item \textbf{getState}: alle aktuelle Zustände zu bekommen.
      \item \textbf{get}: bestimmte Zustand zu bekommen.
      \item \textbf{getIn}: bestimmte Zustand in tiefen Ebenen zu bekommen.
      \item \textbf{set}: bestimmte Zustand zu aktualisieren. Durch der Funktion Notify von Observable die neue Zustände an allen Observer auszuteilen.
      \item \textbf{setIn}: bestimmte Zustand in tiefen Ebenen zu aktualisieren. Durch der Funktion Notify von Observable die neue Zustände an allen Observer auszuteilen.
  \end{itemize}
  
 \subsection{Abschnitte Auswahl}
 Der Auswahl der Abschnitte kann auf zwei Zeitpunkten durchgeführt werden. Einer davon ist während der Aufruf der Applikation. Die Ziffer der ausgewählte abschnitt wird durch dem Query string in URL an der Applikation gegeben. Der andere ist vor dem Nahm der Krankenakte in VR Szene. Auf dem Whiteboard werden die Abschnitte aufgelistet, dadurch bestimmter Abschnitt auswählen werden kann.
 
  \subsubsection{Abschnitte Auswahl durch URL}
  Die Zustände werden am Anfang als ursprüngliche Zustände initialisiert. Durch der Funktion getSectionSelectionFromURL in Class stateIndex kann die ausgewählte Ziffer bestimmen werden. Wenn die Ziffer zwischen 1 und 7 ist, werden die betreffende Zustände durch die Funktion selectSection aktualisiert. Danach werden die Objekte in der Szene nach den Zuständen auch aktualisiert.
  
  Um die GUI richtig einzusetzen, wird ein Trick benutzt. Wenn die Applikation aufgerufen, wird die Szene nach den aktuellen Zuständen eingerichtet und werden gleichzeitig die Modells geladen. Es könnte passieren, dass das Modell noch nicht fertig geladen ist, wenn es von der Aktualisierung betroffen wird. Das führ zu Fehler der Applikation.
  
  Um das Problem zu lösen, werden die Ladung vor der Aktualisierung überprüft. Mit der Funktion setInterval wird es implementiert, jede 0,5 Sekunde die Zustand der Ladung zu überprüfen. Wenn alle Modells schon geladen ist, wird die Überprüfung beendet und die Szene aktualisiert.
  
  image: Überprüfen die Ladung .........
  
  \subsubsection{Abschnitte Auswahl in VR Szene}
  Auf dem Whiteboard wird die Abschnitte aufgelistet. Durch Zeiger oder Raycaster wird die Funktion selectSection in Class stateIndex mit entsprechendem Parameter aufgerufen, um der Abschnitt zu wechseln.
  
  Vor den Zeichnen auf dem Whitebard werden 7 \glqq toggle box\grqq eingesetzt, dadurch die Funktion selectSection von HTC Vive Controller aufgerufen kann.
  
  image: toggle box für Abschnitt .........
  
  \subsubsection{Möglichkeit der Verbesserung}
  Der Abschnitte Auswahl kann nicht nur während der Initialisierung, sondern auch nach der Initialisierung durchgeführt wird. Deswegen sollen die Funktionen über Abschnitte Auswahl wie selectSection nicht in Class stateIndex eingepackt werden, sondern in eigenen Datei geschrieben werden.
  
 \subsection{Gestaltung der Class Struktur der Objekten}
 Um das Projekt effizient zu entwickeln, wird ein Class Struktur gestaltet, die meisten Objekte in diesem Projekt anpasst. Die Struktur basiert auf die Class Struktur von A-Frame.
 
 \subsubsection{Gestaltung}
 Die Philosophie von A-Frame ist, mit spezifischen HTML Elements die Szene aufzubauen. Ein Element ist eine Kombination der Entitäten von unterschiedlichen Classes. Eine Entität kann ein HTML Element oder ein Attribut eines HTML Elements sein. Das Class in A-Frame wird als Component genannt.
 
 Drei Built-in Objekten von Component sind wichtig.
 \begin{itemize}
     \item \textbf{init} ist eine Funktion, die während der Erstellung einer Entität von Component durchgeführt wird.
     \item \textbf{schema} ist ein JavaScript Objekt, die Attribute von Component speichert.
     \item \textbf{update} ist eine Funktion, die durchgeführt wird, wenn das schema durch HTML geändert wird. Die Initialisierung gilt als eine Änderung von schema, d.h. dass die Funktion update während der Erstellung einer Entität durchgeführt wird. Deswegen muss die Funktion init nicht definiert, wenn die Funktion update existiert.
 \end{itemize}
 Andere Funktionen können auch in Class geschrieben und aufgerufen.
 
 image: A-Frame Component und HTML .........
 
 Der Vorteil ist, dass jede Entität eigne Kopie der Funktionen und Attribute von Component hat. Das bedeutet, dass ein Component(Class) viele Entitäten haben kann. Die Entitäten haben keine Beeinflussung mit einander.
 
 Allerdings wird die Struktur von Component wegen der Nutzung von Observer Pattern neu gestaltet.
 
 Wie der Code von Class Observable gezeigt, dass der Parameter der Funktion subscribe eine Funktion sein soll. Aber die Funktionen, die in Class definiert werden, gelten nicht als eine bestimmter Funktion bei JavaScript. Deshalb müssen die Funktionen, die als oberser benutzt werden, außer dem Class definiert werden, sodass die Entitäten von dem Class die Nachrichten von observable empfangen können. Das führt zu einer suboptimale Situation, dass alle Entität, die durch dem gleichen Class erstellt werden, die selbe Funktion benutzen.
 
 Obwohl die Class Struktur passt sich die Philosophie von A-Frame nicht an, ist es praktisch und geeignet für diesem Projekt, weil selten gleiche Objekten, die von Zusände controlliert werden, in der Szene existieren.
 
 Um die Attribute und Funktionen von Component von die Funktion in observer zu erreichen, werden die Attribute und Funktionen beispielsweise schema auch außer dem Class (global) geschrieben.
 
 image: eigne spezielle Component Struktur .........
 
 \subsubsection{Möglichkeit der Verbesserung}
 Es ist auch möglich, nach der Philosophie von A-Frame die Class Struktur zu gestalten.
 
 Durch angepassend \glqq eventlistener\grqq\, die während der Initialisierung eingefügt wird, kann die Nachricht von observable in dem Class transportiert wird.
 
 image: bessere Struktur .........
 
 \subsection{Interaktion}
  Für unterschiedlichen Geräten werden entsprechend Interaktionen konzipiert. Die Implementierungen werden nach Geräten erzählt.
  \subsubsection{PC und Smartphone}
  Viele Interaktionen von PC und Smartphone werden durch selbem Component umgesetzt, deswegen werden PC und Smartphone hier zusammen erklärt.
  
  \textbf{Exploration}
  
  Mit einer Entität von built-in Component \glqq a-camera\grqq in A-Frame wird ein Kamera in der Szene eingesetzt. Dadurch wird die Sicht von Benutzer in der VR Umgebung erstellt. Die Interaktionen, die das Kamera betreffen, nämlich Exploration und Navigation werden in dieser Entität realisiert.
  
  Mit dem Component \glqq look-controls\grqq kann die Rotation einer Entität manipuliert werden. Wenn \grqq look-controls\grqq als Attribut von \glqq a-camera\grqq eingesetzt wird, wird es realisiert, die Drehung der Kamera zu manipulieren.
  
  Wenn die Eigenschaft \glqq pointerLockEnabled\grqq von \glqq look-controls\grqq  als true eingerichtet wird, wird der Zeiger auf PC durch ein Click auf Maus versteckt, und wird Kamera durch der Bewegung von Maus gedreht. Wenn ESC Taste auf Tastatur gedrückt wird, wird der Zeiger wieder gezeigt, und verliert der Maus die Kontrolle der Rotation der Kamera.
  
  Außerdem is es möglich, durch das Ziehen auf dem Smartphone die Kamera zu drehen, wenn die Eigenschaft \glqq touchEnabled\grqq als true konfiguriert. True ist die Standardeinstellung für \glqq touchEnabled\grqq, deswegen muss es nicht extra eingerichtet werden.
  
  \textbf{Navigation}
  
  Mit dem Component \glqq wasd-controls\grqq kann die Position einer Entität manipuliert werden. Die Nutzung ist ähnlich wie das Component \glqq look-controls\grqq. Wenn \grqq wasd-controls\grqq als Attribut von \glqq a-camera\grqq eingesetzt wird, wird die Position der Kamera mit den Tasten W, A, S und D auf der Tastatur zu manipulieren.
  
  Die Eigenschaft \glqq acceleration\grqq beschreibt die Geschwindigkeit der Bewegung, wenn die Teste gedrückt. Um der Schwindel zu vermeiden, wird die Wert ziemlich klein eingerichtet.
  
  Es gibt noch Bug bei dem Component \glqq wasd-controls\grqq. Die manuelle Navigation kann mit Firefox richtig durchgeführt werden. Aber mit Chrome kann die Bewegung nicht beendet werden.
  
  image: code a-camera .........
  
  Außer der manuelle Navigation wird auch die automatische Navigation implementiert. Das Event \glqq raycaster-intersected\grqq wird auf der selbe Objekt emittiert, wenn das Objekt mit Zeiger überlappt. Dann bewegt sich die Kamera zu dem Objekt. Nach sechs Sekunden geht die Kamera wieder zurück. Wenn die Aktivitäten auf einem Objekt fertig ist, empfängt das Objekt das Event nicht mehr.
  
  image: code camera move .........
  
  \textbf{Manipulation}
  
  Die Manipulation auf PC und Smartphone wird mit dem built-in Component \glqq a-cursor\grqq implementiert. Um der Zeiger in der Mitte der Sicht darzustellen, wird \glqq a-cursor\grqq als ein Child-Component von \glqq a-camera\grqq eingesetzt.
  
  Das Attribut \glqq objects\grqq beschreibt, mit welchen Objekten kann man interagieren. Alle solche Objekte werden mit Class \glqq clickable\grqq bezeichnet. Mit dem Attribut \glqq geometry\grqq wird der Zeiger als ein Ring definiert.
  
  Als Standardeinstellung wird der Zeiger auf PC aktiviert, wenn die linke Taste von dem Maus gedruckt. Mit dem Attribut \glqq fuse-timeout\grqq wird die Methode, der Zeiger zu aktivieren, auf Smartphone konfiguriert. Die Wert 1000 bedeutet, dass der Zeiger aktiviert wird, wenn der Zeiger auf einem Objekt 1 Sekunde fokussiert.
  
  Das Attribut \glqq raycaster-intersection\grqq ist eine Entität von Class \glqq raycaster-intersection\grqq, das die Funktion zu realisieren, dass der Zeiger zu grün wechseln, wenn der Zeiger die Objekte trifft, damit interagieren kann.
  
  Das Event \glqq raycaster-intersection\grqq wird auf die Entität selbe emittiert, wenn das raycaster sich mit Objekten überlappt. Im Gegenteil wird \glqq raycaster-intersection-cleard\grqq emittiert, wenn nichts mit das Raycaster überlappt.
  
  Da \glqq a-cursor\grqq hat die Eigenschaften von raycaster integriert, sind \glqq raycaster-intersection\grqq und \glqq raycaster-intersection-cleard\grqq für \glqq a-cursor\grqq zu Verfügung.
  
  image: raycaster-intersection .........
  
  Das Attribut \glqq cursor-submit\grqq ist zuständig für die Funktion, der Zeiger in Rot darzustellen und ein entsprechendes Geräusch zu klingen, wenn der Zeiger aktiviert wird. 
  
  image: cursor-submit .........
  
  \subsubsection{Samsung Gear VR}
  Die Interaktionen für Samsung Gear VR sind abhängig von der Verfügbarkeit des Controllers.
  
  \textbf{Ohne Controller}
  
  Die Interaktionen von Samsung Gear VR ohne Controller sollen von die Funktionen für PC und Smartphone durch A-Frame automatisch angepasst. Allerdings taucht ein Problem bei der Anpassung an Gear VR auf: die Zeiger für jede Auge überlappen sich nicht zusammen. Das heißt, dass zwei Zeiger in der Sicht erscheinen.
  
  Der Grund dafür ist, dass der Zeiger zu nahe zu der Augen. Wenn der Zeiger weiter zu der Augen gelegt wird, ist der Zeiger eindeutig. Jedoch das führt zu der Situation, dass der Zeiger hinter dem Objekt wie Krankenakte ist. Wenn die Krankenakte auch weiter eingesetzt wird, können die Informationen auf der Krankenakte nicht deutlich gesehen werden.
  
  Zwei mögliche Lösungen werden versucht, Raycaster und große Skalierung.
  \begin{itemize}
      \item Raycaster: Die Idee Raycaster ist, das Raycaster von Controller zu den Augen zu bringen. Der Zeiger ist nicht mehr ein Ring, sondern eine aus Augen ausstrahlende Linie, sodass der Abstand zwischen Augen und Objekte keine Rolle spielt. Allerdings wird das Raycaster in Gear VR nicht richtig dargestellt. Die Linie wird als viele kurze Stückchen geschnitten. Und die Stückchen zeigen nicht nach eine einzige Richtung. Sodass kann die Lösung nicht eingesetzt werden.
      
      image: Raycaster for GearVR .........
      
      \item große Skalierung: Der Zeiger und die andere Objekten werden weit gelegt. Um die Objekten deutlicher zu schauen, werden alle Objekten vergrößern, sodass die relative Große sich nicht verändert. Die Position der Kamera wird dafür angepasst.
      
      Das ist keine optimale Lösung, weil der Benutzer fühlen sich, dass selbe ein Gigant ist. Allerdings ist es besser als Raycaster, deswegen wird diese Lösung eingesetzt.
      
      image: Gear VR Skalierung .........
      
  \end{itemize}
  
  \textbf{Mit Controller}
  
  Die Navigation und Manipulation werden durch den Controller aktiviert.
  
  Das Element von Gear VR Controller wird mit dem Element von Kamera zusammen in dem Element mit ID \glqq cameraRig\grqq\ eingepackt. Die Bewegung der Kamera wird durch die Translation von \glqq cameraRig\grqq\ geschafft, sodass wird die relative Position zwischen der Kamera und dem Controller während der Bewegung behaltet.
  
  Mit dem built-in Component \glqq teleport-controls\grqq\ werden die Navigation implementiert. Das Attribut \glqq cameraRig\grqq\ beschreibt das Element, das sich zur den bezeichneten Position bewegt. Das Attribut \glqq teleportOrigin\grqq\ beschreibt das Element, das als die Ursprung von dem Element \glqq cameraRig\grqq\ gilt.
  
  Wenn der Trackpad auf Gear VR Controller gedrückt wird, wird die Position bezeichnet. Solange der Trackpad losgelöst wird, bewegt sich das Element \glqq cameraRig\grqq\ zur den bezeichneten Position. Die Position der Kamera auf den x und z Achsen sind gleich wie die bezeichnete Position. 
  
  Test!!! gearvr-controls vs leser controls
  
  \subsubsection{HTC Vive}
  
  Die Navigation von HTC Vive wird durch dem Component \glqq teleport-controls\grqq\ gleich wie Gear VR implementiert.
  
  \textbf{Component vive-controls}
  
  Durch dem built-in Component \glqq vive-controls\grqq\ werden die Vive Controllers anerkannt. Mit dem Attribut \glqq modl\grqq\ wird die Darstellung des Modells von Controller konfiguriert. Da der Controllers als Hände gezeigt, wird das Attribut als false eingerichtet.
  
  image: vive-controls element .........
  
  Nach der Erkennung der Controllers wird ein Events \glqq triggerdown\grqq\ und \glqq triggerup\grqq\ ausgelöst, wenn der Auslöser gedrückt und losgelöst. Um die Nachrichten über die Aktivität der Controllers auszubreiten, wird Observer Pattern verwendet.
  
  Die relevante Funktionen bei unterschiedlichen Objekten melden sich bei den Observerables für \glqq triggerdown\grqq\ und \glqq triggerup\grqq\ an. Wenn der Auslöser gedrückt oder losgelöst, wird die Informationen(Name von Event, ID von Controller, globale Position von Controller) an alle Observers geschickt.
  
  image: code controller 6d ..........
  
  Um die globale Position zu rechnen, wird die Funktion von three.js verwendet. Die A-Frame Objekte sind eigentliche verpackte three.js Objekte, deswegen ist die Vervwendung von three.js in A-Frame barrierefrei. Das ist ein Vorteil für A-Frame.
  
  image: code getWordPosition ........
  
  \textbf{Prüfung mit Raycaster}
  
  Ein aus Augen ausstrahlendes verstecktes Raycaster in dem Element \glqq a-camera\grqq\ eingesetzt. Wenn die Krankenakte, Infusionsflasche und Infusionsbesteck überprüft werden sollen, wird das Raycaster gezeigt, um die Überprüfung durchzuführen. Wenn das Raycaster die richtige Position trifft, Event \glqq raycaster-intersection\grqq\ ausgelöst wird, wird das Raycaster in grün dargestellt, sonst in orange. Wenn die Überprüfung fertig ist, die Zustände für die Prüfungen true sind ,wird das Raycaster wieder versteckt.
  
  image: code raycaster vive .........
  
  \textbf{Zustände für Vive Controller}
  
  Weil die Manipulation mit Vive Controller große Freiheit hat, und nicht jede Ausführung einer Aktivität den Fortschritt fördert, werden eine neue Liste für die Zustände der Vive Controllers und die entsprechenden Funktionen erstellt.
  
  Zum Beispiel wird die Wert des Zustands für Vive Controller \glqq portfolioInHand\grqq\ als das ID des Controller, der mit der Krankenakte interagiert, gespeichert, und die Zustände an die Observers(Krankenakte usw.) geschickt. Solange die Änderung des Zustands im Component Krankenakte erkannt wird, wird das Element der Krankenakte in dem Element des entsprechenden Controllers eingezogen.
  
  image: code controllerstate, portfolio
  
  \textbf{Attribute Veränderung}
  
  Wenn ein Element in dem Controller Element eingezogen oder aus dem Controller ausgezogen wird, wird die Dimension der Koordination geändert. Deshalb muss das Attribut Position neu gerechnet und umgesetzt.
  
  Normalerweise kann das Attribut direkt mit dem Befehl \glqq setAttribute\grqq konfiguriert werden. Allerdings sind die 3D A-Frame Objekte viel größer als 2D Objekte, sodass die DOM Manipulation länger dauert. Deshalb passiert es, dass die Änderung des Attributs vor dem Umzug des DOM Elements geschafft wird. Und nach dem Umzug wird das Attribut wieder zurückgesetzt.
  
  Um das Problem zu lösen, muss die DOM Funktion \glqq MutationObserver\grqq\ verwendet. Die Funktion \glqq MutationObserver\grqq\ ist zuständig dafür, die Änderung der gegebenen Attribute eines Elements zu beobachten. Wenn die Änderung fertig ist, wird eine Nachricht an den allen Observers geschickt.
  
  Weil die DOM Manipulation sehr häufig ist und fast alle aufwendige Änderungen mit den Controllers zu tun haben, wird die Funktion \glqq MutationObserver\grqq\ in einem Class \glqq controllerActions\grqq\ verpackt, um die Verwendung zu vereinfachen.
  
  Die \glqq MutationObserver\grqq\ beochatet die \glqq childList\grqq\ des eingegebenen Controllers. Wenn die Einfügung und Entfernung der Child Elements des Controllers fertig ist, werden die eingegebene Attribute eingesetzt. 
  
  image: controllerAction .........
  
  \textbf{Hinweis-Box}
  
  Die Hinweis-Box wird durch das built-in Element a-box implementiert. Durch die Konfiguration des Attributs \glqq material\grqq\ wird die Hinweis-Box in halb transparentem Rot dargestellt, wenn ein Objekt beispielsweise Krankenakte in Hand ist. Die Hinweis-Box hört zu den Zuständen aller Objekten. Wenn alle nötige Aktivitäten für das Objekt fertig gemacht, z.B. Überprüfung der Krankenakte, werden die Änderungen der entsprechenden Zuständen von der Hinweis-Box erkannt. Nach der Erkennung wird das Attributs \glqq material\grqq\ zum Grün umgeschrieben.
  
  Wenn die Kollision zwischen der grüne Hinweis-Box und dem Objekt in Hand während des Loslösens auf den Auslöser des Controllers detektiert wird, wird der entsprechende Zustand geändert und das Objekt auf die Arbeitsfläche gelegt.
  
  image: code HTML toggleBoxPortfolio .........
  image: code class toggleBoxPortfolio .........
  
  \textbf{Kollision Detektion}
  
  Die Funktion Kollision Detektion wird durch die Funktionen von three.js implementiert. Die zwei Objekte werden erst durch die Funktion \glqq setFromObject\grqq\ als Kuben umgerechnet. Durch die Funktion \glqq intersectsBox\grqq\ wird es überprüft, ob zwei Kuben überlappt sind, damit die Kollision zu Detektieren.
  
  Allerdings ist die Methode keine optimale Lösung. Wenn das Objekt kein Kubus ist, ist die Detektion ungenau.
  
  image: code collision detection.
  
  \textbf{Fallen}
  
  Die Objekte können aus den Händen fallen. Um der Fall zu simulieren, werden die Position auf Y Achse 
  
  \textbf{Arbeitsoberfläche Desinfektion in Vive}
  
  image: tabelle Interaktion Component .........
  
 \subsection{Geräte anpassen}
 \subsection{Töne}
 \subsection{Uhr}
 \subsection{Hand}
 
 \subsection{Animation}
 \subsection{Transparenz}
 
 \subsection{Arbeitsoberfläche Desinfektion in Vive}
 \subsection{Kollision Erkennung}
 \subsection{Fallen}


